{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import itertools\n",
    "from random import shuffle\n",
    "from math import log\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human interface computer', 'survey user computer system response time', 'eps user interface system', 'system human system eps', 'user response time', 'trees', 'graph trees', 'graph minors trees', 'graph minors survey', 'I like graph and stuff', 'I like trees and stuff', 'Sometimes I build a graph', 'Sometimes I build trees']\n"
     ]
    }
   ],
   "source": [
    "test_corpus = (\"\"\"human interface computer\n",
    "survey user computer system response time\n",
    "eps user interface system\n",
    "system human system eps\n",
    "user response time\n",
    "trees\n",
    "graph trees\n",
    "graph minors trees\n",
    "graph minors survey\n",
    "I like graph and stuff\n",
    "I like trees and stuff\n",
    "Sometimes I build a graph\n",
    "Sometimes I build trees\"\"\").split(\"\\n\")\n",
    "\n",
    "print(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': (0, 2),\n",
       " 'interface': (1, 2),\n",
       " 'computer': (2, 2),\n",
       " 'survey': (3, 2),\n",
       " 'user': (4, 3),\n",
       " 'system': (5, 4),\n",
       " 'response': (6, 2),\n",
       " 'time': (7, 2),\n",
       " 'eps': (8, 2),\n",
       " 'trees': (9, 5),\n",
       " 'graph': (10, 5),\n",
       " 'minors': (11, 2),\n",
       " 'I': (12, 4),\n",
       " 'like': (13, 2),\n",
       " 'and': (14, 2),\n",
       " 'stuff': (15, 2),\n",
       " 'Sometimes': (16, 2),\n",
       " 'build': (17, 2),\n",
       " 'a': (18, 1)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_vocab(corpus):\n",
    "    \"\"\"\n",
    "    Build a vocabulary with word frequencies for an entire corpus.\n",
    "    Returns a dictionary `w -> (index, frequency)`, mapping word strings to pairs of\n",
    "    word ID and word corpus frequency.\n",
    "    \"\"\"\n",
    "\n",
    "    vocab_dict = {}\n",
    "    for line in corpus:\n",
    "        words = line.strip().split(\" \")\n",
    "        for word in words:\n",
    "            if word not in vocab_dict:\n",
    "                vocab_dict[word] = 1\n",
    "            else:\n",
    "                vocab_dict[word] +=1\n",
    "\n",
    "    word_index_count_dict = {}\n",
    "    word_count = 0\n",
    "    for word in vocab_dict:\n",
    "        word_index_count_dict[word] = (word_count , vocab_dict[word])\n",
    "        word_count = word_count + 1\n",
    "\n",
    "    return word_index_count_dict\n",
    "\n",
    "build_vocab(test_corpus) #인덱스랑 전체 빈도 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cooccur(vocab, corpus, window_size=3, min_count=None):\n",
    "    vocab_size = len(vocab)\n",
    "    id_word = {}\n",
    "\n",
    "    for word in vocab:\n",
    "        id_word[vocab[word][0]] = word\n",
    "\n",
    "    word_id = {id_word[id_]:id_ for id_ in id_word}\n",
    "\n",
    "\n",
    "    #sparse lil_matrix is optimized to operate on matrix which mostly has zeros.    \n",
    "    cooccurrences = sparse.lil_matrix((vocab_size, vocab_size),dtype=np.float64)\n",
    "\n",
    "    for i, line in enumerate(corpus):\n",
    "\n",
    "        senetence = line.strip().split()\n",
    "        #Get the ID of words from vocab dictionary\n",
    "        word_ids = [vocab[word][0] for word in senetence]\n",
    "        #print word_ids\n",
    "\n",
    "        for i, center_word_id in enumerate(word_ids):\n",
    "            #Get all the left side words within the window size.    \n",
    "            left_context_word_ids  = word_ids[max(0, i-window_size):i]\n",
    "\n",
    "            #Get all the right side words within the window size. \n",
    "            right_context_word_ids = word_ids[i+1: i+window_size]\n",
    "\n",
    "            #Now update the cooccurrence matrix for the current center word \n",
    "            #using the context words list.\n",
    "            #First do for the left context part and then for right context part\n",
    "            cooccurrences = update_cooccurrence_matrix(cooccurrences, left_context_word_ids, center_word_id,\"left_context\")\n",
    "            cooccurrences = update_cooccurrence_matrix(cooccurrences, right_context_word_ids, center_word_id,\"right_context\")\n",
    "\n",
    "    # Now yield our tuple sequence (dig into the LiL-matrix internals to\n",
    "    # quickly iterate through all nonzero cells)\n",
    "    cooccurrences_tuples = []\n",
    "    for i, (row, data) in enumerate(zip(cooccurrences.rows,cooccurrences.data)):\n",
    "        \n",
    "        print(i, row, data)\n",
    "        if min_count is not None and vocab[id_word[i]][1] < min_count:\n",
    "            continue\n",
    "\n",
    "        for data_idx, j in enumerate(row):\n",
    "            if min_count is not None and vocab[id_word[j]][1] < min_count:\n",
    "                continue\n",
    "\n",
    "            cooccurrences_tuples.append((i, j, float(data[data_idx])))\n",
    "            #yield i, j, data[data_idx] \n",
    "\n",
    "    print(cooccurrences)\n",
    "    return cooccurrences_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cooccurrence_matrix(cooccurrences, context_word_ids, center_word_id, side):\n",
    "    #Update cooccurrence matrix based on the distance of the context word\n",
    "    #from the center word. The logic for getting the context words is:\n",
    "    \"\"\"\n",
    "    sentence = [10, 20, 50, 60, 70]\n",
    "    Let center word be 50 and window size =2\n",
    "    left_context =[10,20]\n",
    "    right_context = [60,70]\n",
    "    Updating weights:\n",
    "    left context - Since 20 is close to 50, it has to be given a weight of 1\n",
    "                   Since 10 is one step far from 50, it has to be given a weight of 1/2\n",
    "    right context - Since 60 is close to 50, it has to be given a weight of 1\n",
    "                    Since 70 is one step far from 50, it has to be given a weight of 1/2\n",
    "    Logic of updating cooccurrence: The logic is based on the distance from center word.\n",
    "    But the right context word list has to be reversed to apply one single logic for both\n",
    "    left and right context window. The elements at the end of the list are closer to center word.\n",
    "    For instance in the left_context_list\n",
    "    \"\"\"\n",
    "\n",
    "    if side == \"right_context\":\n",
    "      context_word_ids.reverse() \n",
    "\n",
    "    #len of context_word_ids will be used while calculating distance\n",
    "    number_of_context_words = len(context_word_ids) \n",
    "\n",
    "    for i in range(number_of_context_words):\n",
    "        distance = number_of_context_words - i\n",
    "        weight = 1 / float(distance)\n",
    "\n",
    "        #center word will act as the row and the context word is the column\n",
    "        cooccurrences[center_word_id, context_word_ids[i]] += weight\n",
    "\n",
    "    return cooccurrences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1, 2, 5, 8] [1.0, 0.5, 2.0, 0.5]\n",
      "1 [0, 2, 4, 5, 8] [1.0, 1.0, 1.0, 1.0, 0.5]\n",
      "2 [0, 1, 3, 4, 5, 6] [0.5, 1.0, 0.5, 1.0, 1.0, 0.5]\n",
      "3 [2, 4, 10, 11] [0.5, 1.0, 0.5, 1.0]\n",
      "4 [1, 2, 3, 5, 6, 7, 8] [1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0]\n",
      "5 [0, 1, 2, 3, 4, 5, 6, 7, 8] [2.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 1.3333333333333333]\n",
      "6 [2, 4, 5, 7] [0.5, 1.3333333333333333, 1.0, 2.0]\n",
      "7 [2, 4, 5, 6] [0.3333333333333333, 0.5, 0.5, 2.0]\n",
      "8 [0, 1, 4, 5] [0.5, 0.5, 1.0, 1.3333333333333333]\n",
      "9 [10, 11, 12, 13, 14, 15, 16, 17] [1.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333, 1.0]\n",
      "10 [3, 9, 11, 12, 13, 14, 15, 17, 18] [0.5, 1.5, 2.0, 0.8333333333333333, 1.0, 1.0, 0.5, 0.5, 1.0]\n",
      "11 [3, 9, 10] [1.0, 1.0, 2.0]\n",
      "12 [9, 10, 13, 16, 17, 18] [1.0, 0.5, 2.0, 2.0, 2.0, 0.5]\n",
      "13 [9, 10, 12, 14] [1.0, 1.0, 2.0, 1.0]\n",
      "14 [9, 10, 12, 13, 15] [1.0, 1.0, 0.6666666666666666, 1.0, 2.0]\n",
      "15 [9, 10, 13, 14] [0.5, 0.5, 0.6666666666666666, 2.0]\n",
      "16 [12, 17] [2.0, 1.0]\n",
      "17 [9, 10, 12, 16, 18] [1.0, 0.5, 2.0, 1.0, 1.0]\n",
      "18 [10, 12, 16, 17] [1.0, 0.5, 0.3333333333333333, 1.0]\n",
      "  (0, 1)\t1.0\n",
      "  (0, 2)\t0.5\n",
      "  (0, 5)\t2.0\n",
      "  (0, 8)\t0.5\n",
      "  (1, 0)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 5)\t1.0\n",
      "  (1, 8)\t0.5\n",
      "  (2, 0)\t0.5\n",
      "  (2, 1)\t1.0\n",
      "  (2, 3)\t0.5\n",
      "  (2, 4)\t1.0\n",
      "  (2, 5)\t1.0\n",
      "  (2, 6)\t0.5\n",
      "  (3, 2)\t0.5\n",
      "  (3, 4)\t1.0\n",
      "  (3, 10)\t0.5\n",
      "  (3, 11)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (4, 2)\t1.0\n",
      "  (4, 3)\t1.0\n",
      "  (4, 5)\t1.0\n",
      "  (4, 6)\t1.0\n",
      "  (4, 7)\t0.5\n",
      "  (4, 8)\t1.0\n",
      "  (5, 0)\t2.0\n",
      "  (5, 1)\t1.0\n",
      "  (5, 2)\t1.0\n",
      "  (5, 3)\t0.3333333333333333\n",
      "  (5, 4)\t1.0\n",
      "  (5, 5)\t1.0\n",
      "  (5, 6)\t1.0\n",
      "  (5, 7)\t0.5\n",
      "  (5, 8)\t1.3333333333333333\n",
      "  (6, 2)\t0.5\n",
      "  (6, 4)\t1.3333333333333333\n",
      "  (6, 5)\t1.0\n",
      "  (6, 7)\t2.0\n",
      "  (7, 2)\t0.3333333333333333\n",
      "  (7, 4)\t0.5\n",
      "  (7, 5)\t0.5\n",
      "  (7, 6)\t2.0\n",
      "  (8, 0)\t0.5\n",
      "  (8, 1)\t0.5\n",
      "  (8, 4)\t1.0\n",
      "  (8, 5)\t1.3333333333333333\n",
      "  (9, 10)\t1.5\n",
      "  (9, 11)\t1.0\n",
      "  (9, 12)\t1.0\n",
      "  (9, 13)\t1.0\n",
      "  (9, 14)\t1.0\n",
      "  (9, 15)\t0.5\n",
      "  (9, 16)\t0.3333333333333333\n",
      "  (9, 17)\t1.0\n",
      "  (10, 3)\t0.5\n",
      "  (10, 9)\t1.5\n",
      "  (10, 11)\t2.0\n",
      "  (10, 12)\t0.8333333333333333\n",
      "  (10, 13)\t1.0\n",
      "  (10, 14)\t1.0\n",
      "  (10, 15)\t0.5\n",
      "  (10, 17)\t0.5\n",
      "  (10, 18)\t1.0\n",
      "  (11, 3)\t1.0\n",
      "  (11, 9)\t1.0\n",
      "  (11, 10)\t2.0\n",
      "  (12, 9)\t1.0\n",
      "  (12, 10)\t0.5\n",
      "  (12, 13)\t2.0\n",
      "  (12, 16)\t2.0\n",
      "  (12, 17)\t2.0\n",
      "  (12, 18)\t0.5\n",
      "  (13, 9)\t1.0\n",
      "  (13, 10)\t1.0\n",
      "  (13, 12)\t2.0\n",
      "  (13, 14)\t1.0\n",
      "  (14, 9)\t1.0\n",
      "  (14, 10)\t1.0\n",
      "  (14, 12)\t0.6666666666666666\n",
      "  (14, 13)\t1.0\n",
      "  (14, 15)\t2.0\n",
      "  (15, 9)\t0.5\n",
      "  (15, 10)\t0.5\n",
      "  (15, 13)\t0.6666666666666666\n",
      "  (15, 14)\t2.0\n",
      "  (16, 12)\t2.0\n",
      "  (16, 17)\t1.0\n",
      "  (17, 9)\t1.0\n",
      "  (17, 10)\t0.5\n",
      "  (17, 12)\t2.0\n",
      "  (17, 16)\t1.0\n",
      "  (17, 18)\t1.0\n",
      "  (18, 10)\t1.0\n",
      "  (18, 12)\t0.5\n",
      "  (18, 16)\t0.3333333333333333\n",
      "  (18, 17)\t1.0\n"
     ]
    }
   ],
   "source": [
    "cooccurrences = build_cooccur(vocab, test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
