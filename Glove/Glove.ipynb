{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import itertools\n",
    "from random import shuffle\n",
    "from math import log\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human interface computer', 'survey user computer system response time', 'eps user interface system', 'system human system eps', 'user response time', 'trees', 'graph trees', 'graph minors trees', 'graph minors survey', 'I like graph and stuff', 'I like trees and stuff', 'Sometimes I build a graph', 'Sometimes I build trees']\n"
     ]
    }
   ],
   "source": [
    "test_corpus = (\"\"\"human interface computer\n",
    "survey user computer system response time\n",
    "eps user interface system\n",
    "system human system eps\n",
    "user response time\n",
    "trees\n",
    "graph trees\n",
    "graph minors trees\n",
    "graph minors survey\n",
    "I like graph and stuff\n",
    "I like trees and stuff\n",
    "Sometimes I build a graph\n",
    "Sometimes I build trees\"\"\").split(\"\\n\")\n",
    "\n",
    "print(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': (0, 2),\n",
       " 'interface': (1, 2),\n",
       " 'computer': (2, 2),\n",
       " 'survey': (3, 2),\n",
       " 'user': (4, 3),\n",
       " 'system': (5, 4),\n",
       " 'response': (6, 2),\n",
       " 'time': (7, 2),\n",
       " 'eps': (8, 2),\n",
       " 'trees': (9, 5),\n",
       " 'graph': (10, 5),\n",
       " 'minors': (11, 2),\n",
       " 'I': (12, 4),\n",
       " 'like': (13, 2),\n",
       " 'and': (14, 2),\n",
       " 'stuff': (15, 2),\n",
       " 'Sometimes': (16, 2),\n",
       " 'build': (17, 2),\n",
       " 'a': (18, 1)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_vocab(corpus):\n",
    "    \"\"\"\n",
    "    Build a vocabulary with word frequencies for an entire corpus.\n",
    "    Returns a dictionary `w -> (index, frequency)`, mapping word strings to pairs of\n",
    "    word ID and word corpus frequency.\n",
    "    \"\"\"\n",
    "\n",
    "    vocab_dict = {}\n",
    "    for line in corpus:\n",
    "        words = line.strip().split(\" \")\n",
    "        for word in words:\n",
    "            if word not in vocab_dict:\n",
    "                vocab_dict[word] = 1\n",
    "            else:\n",
    "                vocab_dict[word] +=1\n",
    "\n",
    "    word_index_count_dict = {}\n",
    "    word_count = 0\n",
    "    for word in vocab_dict:\n",
    "        word_index_count_dict[word] = (word_count , vocab_dict[word])\n",
    "        word_count = word_count + 1\n",
    "\n",
    "    return word_index_count_dict\n",
    "\n",
    "build_vocab(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cooccur(vocab, corpus, window_size=3, min_count=None):\n",
    "    vocab_size = len(vocab)\n",
    "    id_word = {}\n",
    "\n",
    "    for word in vocab:\n",
    "        id_word[vocab[word][0]] = word\n",
    "\n",
    "    word_id = {id_word[id_]:id_ for id_ in id_word}\n",
    "\n",
    "    save_model(id_word, path=\"id2word.pkl\")\n",
    "    save_model(word_id, path=\"word2id.pkl\")\n",
    "\n",
    "    #sparse lil_matrix is optimized to operate on matrix which mostly has zeros.    \n",
    "    cooccurrences = sparse.lil_matrix((vocab_size, vocab_size),dtype=np.float64)\n",
    "\n",
    "    for i, line in enumerate(corpus):\n",
    "\n",
    "        senetence = line.strip().split()\n",
    "        #Get the ID of words from vocab dictionary\n",
    "        word_ids = [vocab[word][0] for word in senetence]\n",
    "        #print word_ids\n",
    "\n",
    "        for i, center_word_id in enumerate(word_ids):\n",
    "            #Get all the left side words within the window size.    \n",
    "            left_context_word_ids  = word_ids[max(0, i-window_size):i]\n",
    "\n",
    "            #Get all the right side words within the window size. \n",
    "            right_context_word_ids = word_ids[i+1: i+window_size]\n",
    "\n",
    "            #Now update the cooccurrence matrix for the current center word \n",
    "            #using the context words list.\n",
    "            #First do for the left context part and then for right context part\n",
    "            cooccurrences = update_cooccurrence_matrix(cooccurrences, left_context_word_ids, center_word_id,\"left_context\")\n",
    "            cooccurrences = update_cooccurrence_matrix(cooccurrences, right_context_word_ids, center_word_id,\"right_context\")\n",
    "\n",
    "    # Now yield our tuple sequence (dig into the LiL-matrix internals to\n",
    "    # quickly iterate through all nonzero cells)\n",
    "    cooccurrences_tuples = []\n",
    "    for i, (row, data) in enumerate(itertools.izip(cooccurrences.rows,cooccurrences.data)):\n",
    "        \n",
    "        print(i, row, data)\n",
    "        if min_count is not None and vocab[id_word[i]][1] < min_count:\n",
    "            continue\n",
    "\n",
    "        for data_idx, j in enumerate(row):\n",
    "            if min_count is not None and vocab[id_word[j]][1] < min_count:\n",
    "                continue\n",
    "\n",
    "            cooccurrences_tuples.append((i, j, float(data[data_idx])))\n",
    "            #yield i, j, data[data_idx] \n",
    "\n",
    "    print(cooccurrences)\n",
    "    return cooccurrences_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
